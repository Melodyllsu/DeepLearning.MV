> 参考链接:  https://blog.csdn.net/weifenglin1997/article/details/77609598    

神经网络的学习主要蕴含在权重和阈值中，多层网络使用上面简单感知机的权重调整规则显然不够用了，  
BP神经网络算法即误差逆传播算法正是为学习多层前馈神经网络而设计，BP神经网络算法是迄今为止最成功的的神经网络学习算法。    
*一般而言，只需包含一个足够多神经元的隐层，就能以任意精度逼近任意复杂度的连续函数.*    
- 定义：多层前馈神经网络  
- 特点：信号前向传播，误差反向传播    
- 阶段：1.信号的前向传播，输入层->隐含层->输出层；2.误差的反向传播，输出层->隐含层->输入层，依次调节隐含层到输出层的权重和偏置，输入层到隐含层的权重和偏置。  
- 结构：典型的三层神经网络的基本构成，Layer L1是输入层，Layer L2是隐含层，Layer L3是隐含层.   

> 隐藏层可以有，也可以没有，输入层和输出层必须要有。没有隐藏层的神经网络是线性的，只能处理线性可分的问题（线性可分问题从二维的角度就是分界线是一条直线，多维就是存在线性超平面将其分类）。
**一个没有隐藏层且输出层只有一个单元的神经网络就相当于线性的Logistic模型**。



## 感知机与多层网络  
感知机（Perceptron）是由两层神经元组成的一个简单模型，  
但只有输出层是M-P神经元，即只有输出层神经元进行激活函数处理，也称为功能神经元（functionalneuron）；  
输入层只是接受外界信号（样本属性）并传递给输出层（输入层的神经元个数等于样本的属性数目），而没有激活函数。  
这样一来，感知机与之前线性回归的思想基本是一样的，都是通过对属性加权与另一个常数求和，再使用sigmoid函数将这个输出值压缩到0-1之间，从而解决分类问题。  
不同的是感知机的输出层应该可以有多个神经元，从而可以实现多分类问题，同时两个模型所用的参数估计方法十分不同。

